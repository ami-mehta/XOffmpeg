{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating animations with Flat and ffmpeg\n",
    "\n",
    "By [Allison Parrish](http://www.decontextualize.com)\n",
    "\n",
    "This notebook demonstrates how to produce animations with [Flat](https://xxyxyz.org/flat), [ipywidgets](https://ipywidgets.readthedocs.io/) and [ffmpeg](https://ffmpeg.org/). The notebook builds on examples from [Material of Language](https://github.com/aparrish/material-of-language/), and in particular assumes that you're familiar with the material in this [interactive widgets tutorial](interactive-widgets.ipynb). In the notebook, I show two techniques for generating animations:\n",
    "\n",
    "* Use [the ipywidgets Play widget](https://ipywidgets.readthedocs.io/en/latest/examples/Widget%20List.html)\n",
    "* Export an image sequence, then convert the image sequence to a video file with `ffmpeg`\n",
    "\n",
    "> Note: There are a number of ways to convert image sequences to video files: here are [instructions for QuickTime Player in macOS Catalina 10.15](https://support.apple.com/guide/quicktime-player/create-a-movie-with-an-image-sequence-qtp315cce984/mac); or see documentation on [similar functionality in Adobe Premiere Pro](https://helpx.adobe.com/premiere-pro/using/importing-still-images.html) and [After Effects](https://helpx.adobe.com/after-effects/using/preparing-importing-still-images.html#import_a_single_still_image_or_a_still_image_sequence). If you have access to those tools and prefer to use them, then you can ignore the content about ffmpeg below.\n",
    "\n",
    "Make sure you have ffmpeg installed before you begin. If you're using macOS, I again recommend using [Homebrew](https://brew.sh/) to install it: `brew install ffmpeg`. You can also install it with Anaconda:\n",
    "\n",
    "    conda install -c conda-forge ffmpeg\n",
    "\n",
    "The notebook assumes that the `ffmpeg` command is available in your shell's path. To check, try running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get a `command not found` error message (or similar), then you either don't have ffmpeg installed, or ffmpeg isn't in your shell's pathâ€”you'll have to fix that problem before you proceed! (If you're in my class, don't hesitate to send me an e-mail and I can help you sort it out.\n",
    "\n",
    "Some code preliminaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flat import document, shape, rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below takes a Flat `page` object and displays it inline in Jupyter notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG, display\n",
    "def show(page):\n",
    "    display(SVG(page.svg()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animating with ipywidgets `Play`\n",
    "\n",
    "For our purposes, we'll define an \"animation\" as a series of images (or \"frames\") that are shown in succession quickly enough that they can produce the illusion of motion (taking advantage of [beta movement](https://en.wikipedia.org/wiki/Beta_movement)). Our strategy for producing an animation in Python is to write a function that takes an integer parameter that indicates the current frame index, and return an image for the corresponding frame. This is close to the way that (e.g.) the `draw()` function in [p5.js](https://p5js.org/) works, except there is no canvas that persists between frames, and you have to call the function yourself for each of the frames you want to generate.\n",
    "\n",
    "The primary strategy for generating an animation in this notebook is writing a function like this and then calling it in a loop. But a super easy way to experiment with animation is [ipywidget's `Play` control](https://ipywidgets.readthedocs.io/en/latest/examples/Widget%20List.html#Play-(Animation)-widget). This widget produces a sequence of increasing integers after you press a \"Play\" button, which you can connect to a function with `widgets.interact()`. Here's a quick example that just prints those integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_val(step=0):\n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_widget = widgets.Play(min=0, max=30, interval=100)\n",
    "widgets.interact(print_val, step=play_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you press the play button, you should see an increasing series of integers. The `interval` parameter sets the number of milliseconds that the `Play` widget waits between calls to the function.\n",
    "\n",
    "To animate a Flat drawing, take your existing (non-animated) code and put it in a function that accepts a parameter and returns a Flat `page` object. The parameter will receive the value from the `Play` widget, which you can think of as the number of the frame that the function should draw in your animation. (In the following examples, I've called this parameter `step`, but you can call it whatever you want.)\n",
    "\n",
    "The code below implements a simple example of this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(step=0):\n",
    "    page = document(80, 80, 'mm').addpage()\n",
    "    page.place(shape().nostroke().fill(rgb(255, 255, 255)).rectangle(0, 0, 80, 80))\n",
    "    page.place(shape().nostroke().fill(rgb(40, 40, 160)).ellipse(40+step, 40, step, step*1.5))\n",
    "    return page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As specified above, this function takes a parameter `step` and returns a Flat `page`. The code in the function creates the page, draws a white rectangle on the page (an opaque background), and then draws a blue ellipse over that rectangle. The size of the ellipse is determined by the `step` parameter.\n",
    "\n",
    "You can call this function with an integer to see what the animation looks like on the corresponding frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(render(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(render(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can animate this with the `Play` widget, although there is a bit of glue that we need first to put everything together. The `render()` function doesn't actually *show* the page, it just *returns* the page. So in order to use this function with `widgets.interact()`, you need a second little function that just shows the page that `render()` returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_and_show(step=0):\n",
    "    show(render(step))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can call `widgets.interact()` with this function and a `Play` widget:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.interact(render_and_show, step=widgets.Play(min=0, max=30, interval=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Note the `interval` parameter: `1000/30` gives us one thousand milliseconds (=one second) divided by thirty, i.e., the number of milliseconds between frames if you want to show thirty frames per second."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting image sequences\n",
    "\n",
    "The technique above (using the `Play` widget) might be enough for you! There is no way to export a video file directly using the `Play` widget, but you could use [licecap](https://www.cockos.com/licecap/) to capture a GIF right from the screen, or do a screen recording with (e.g.) QuickTime Player. The primary disadvantage is that you can't control the actual frame rate: the `Play` widget attempts to update every `interval` milliseconds, but may not actually succeed in drawing that frequently (if, for example, your computer isn't fast enough to render your scene that quickly). You're also limited to generating images whose resolution is less than the size of your browser window.\n",
    "\n",
    "If you want a bit more control over timing and size of your animations, the most flexible workflow involves generating a sequence of image files, then converting those image files to a video file. This is a standard workflow, and is supported by a number of video editing tools. In order to keep things programmatic, open source and cross-platform, we'll be using the excellent [ffmpeg](https://ffmpeg.org/), a command line tool for editing video files.\n",
    "\n",
    "### Generating images with Flat\n",
    "\n",
    "In order to produce a *sequence* of images, we first need to be able to generate a *single* image. Flat provides a built-in means of doing this: the `.image()` method of a `page` object. For example, using the `render()` function above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = render(10)\n",
    "png_bytes = page.image(ppi=72, kind='rgb').png()\n",
    "png_bytes[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chain of method calls evaluates to the binary data of a PNG image, which we could then write to disk. The problem with this technique is that Flat's PNG renderer is *very slow*, potentially taking several hundred milliseconds to render even very simple drawings. A hundred milliseconds doesn't sound like much, but when you're rendering thousands of frames, it can easily add up.\n",
    "\n",
    "For this reason, I recommend using [CairoSVG](https://cairosvg.org/) to render Flat-produced SVG code as PNG images. In my initial round of benchmarking, CairoSVG renders Flat page objects to PNG 30x-50x faster than Flat's built-in code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install CairoSVG with Anaconda, which will also install tricky system dependencies:\n",
    "\n",
    "    conda install -c conda-forge cairosvg\n",
    "    \n",
    "If you're not using Anaconda, you can install using `pip`:\n",
    "\n",
    "    pip install cairosvg\n",
    "    \n",
    "Though I *think* installing from `pip` will lead to trouble if you don't already have [Cairo](https://www.cairographics.org/) installed. (If you're on macOS, I recommend using [Homebrew](https://brew.sh/) to install Cairo: `brew install cairo`.)\n",
    "\n",
    "If none of that works, don't fretâ€”you can use still Flat's built-in PNG renderer. (Just remember that this is a bit slower than using CairoSVG.) The function below takes a Flat page as a parameter, then converts it to a PNG byte string, using CairoSVG if it's available and the Flat's PNG renderer otherwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page2png(page, dpi=72):\n",
    "    try:\n",
    "        import cairosvg\n",
    "        png_bytes = cairosvg.svg2png(page.svg(), dpi=dpi)\n",
    "    except ModuleNotFoundError:\n",
    "        png_bytes = page.image(ppi=dpi, kind='rgb').png()\n",
    "    return png_bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "png_data = page2png(render(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "png_data[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function returns raw PNG data. You can see what it looks like using IPython's `Image()` function, which will automatically recognize the data format and show the image in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(Image(png_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting together filenames\n",
    "\n",
    "Okay, so now we can generate image data from a Flat page. To generate an animation, we need to generate an image for each frame of our animation, and then write that image out to disk as a file. We're potentially going to generate a *lot* of images, so it'll probably be best to put them in a directory on their own. The code in the following cell makes a subdirectory called `render` in the same directory as this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir render"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you just wanted to write a single image, you could do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"render2/test.png\", \"wb\") as fh:\n",
    "    fh.write(page2png(render(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your file browser to check the `render` subdirectory. You should see a file called `test.png` in there. ([More information on reading and writing files in Python](https://realpython.com/read-write-files-python/).)\n",
    "\n",
    "But we need to generate *multiple* frames, and each frame needs its own filename. Furthermore, those filenames should indicate the order in which the image falls in the sequence. The code in the following cell shows how to use a Python f-string to generate a filename for ten frames in a `for` loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    fname = f\"render/image{i:05}.png\"\n",
    "    print(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this code doesn't actually generate the imagesâ€”I just wanted to show how to create the filenames. The leading zeroes are importantâ€”ffmpeg expects them, and in any case the files wouldn't strictly be in alphabetical order without them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing each frame\n",
    "\n",
    "The code below puts it all together. Looping from zero to thirty, it creates a filename, generates PNG data for that frame, then writes the PNG data to the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    fname = f\"render/image{i:05}.png\"\n",
    "    png_data = page2png(render(i))\n",
    "    with open(fname, \"wb\") as fh:\n",
    "        fh.write(png_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls render"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell below should open your operating system's file browser (e.g., macOS Finder) and show the `render` directory. If you enable the file browser's preview function, you can move up and down the file listing and see the animation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!open render"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use [ffmpeg](https://ffmpeg.org/) to convert the image sequence to an animation. The following command uses ffmpeg's `image2` input format, reads from the image sequence, then writes out an `.mp4` file with the H.264 codec and `yuv420p` pixel format (all good defaults for creating cross-platform video files):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -loglevel warning -y \\\n",
    "    -framerate 30 -f image2 -i render/image%05d.png \\\n",
    "    -vcodec libx264 -crf 10 -pix_fmt yuv420p render2/output.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a file called `output.mp4` in the `render` directory that has one second of video.\n",
    "\n",
    "The cell above runs the `ffmpeg` command installed on your system. It's all one command, even though it's on multiple linesâ€”as in Python, the backslash character (`\\`) indicates a line continuation. (I separated it into multiple lines to make it a bit easier to read.) Some explanations of the command line options:\n",
    "\n",
    "* `-loglevel warning`: Restrict output to warnings; without this ffmpeg will print a page or two of informational output. (Which looks cool but isn't terribly interesting in most cases.)\n",
    "* `-y`: Always overwrite existing files without asking for confirmation. (Without this option, ffmpeg will hang if it has to ask you a question when you run it from Jupyter Notebook.)\n",
    "* `-f image2`: Use the `image2` format for input. (This is how you get `ffmpeg` to read a sequence of images.)\n",
    "* `-i render/image%05d.png`: The input parameter for `image2`, which tells `ffmpeg` to look for files whose names match a particular pattern. Check the ffmpeg documentation for [more information about valid filename patterns](https://www.ffmpeg.org/ffmpeg-formats.html#image2-1).\n",
    "* `-vcodec libx264`: This tells `ffmpeg` to use [H.264](https://en.wikipedia.org/wiki/Advanced_Video_Coding) as the output video codec (which is probably always what you want).\n",
    "* `-crf 10`: Controls the quality of the output. Lower is better. (A value of 0 is completely lossless but produces very large files; the maximum value is 51.) [More information on the `crf` parameter](https://trac.ffmpeg.org/wiki/Encode/H.264)\n",
    "* `-pix_fmt yuv420p`: Sets the pixel format for the output video; `yuv420p` is almost certainly what you want. (If you leave out this parameter or use a different value, the video might not work in certain players.)\n",
    "\n",
    "The final parameter is the name of the file that you want to write, the format of which `ffmpeg` guesses by the file extension you specify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display the video in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <video alt=\"rendered output\" controls>\n",
       "        <source src=\"render/output.mp4\" type=\"video/mp4\">\n",
       "    </video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "display(HTML(\"\"\"\n",
    "    <video alt=\"rendered output\" controls>\n",
    "        <source src=\"render/output.mp4\" type=\"video/mp4\">\n",
    "    </video>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also make GIFs with `ffmpeg`. (This example is adapted from the code on this [wonderful Giphy Engineering blog post](https://engineering.giphy.com/how-to-make-gifs-with-ffmpeg/).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -loglevel warning -y \\\n",
    "    -framerate 30 -f image2 -i render/image%05d.png \\\n",
    "    -filter_complex \"[0:v] split [a][b];[a] palettegen [p];[b][p] paletteuse\" render2/output.gif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display a GIF in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(open(\"render2/output.gif\", \"rb\").read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete examples\n",
    "\n",
    "I've written some more complete examples below so you can see how this strategy works in practice. First, a few bits of code we'll use in both of the examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bezmerizing import Polyline, Path\n",
    "from copy import copy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animating letters\n",
    "\n",
    "This example adapts the [\"one character at a time\" example from the Manipulating Fonts notebook](manipulating-font-data.ipynb#One-character-at-a-time). Instead of drawing the characters at random positions once, it draws characters at random positions andâ€”as the number of frames progressesâ€”moves those letters back to their \"original\" positions.\n",
    "\n",
    "Loading the font and copying over some helpful functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flat import font"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = font.open(\"NotoSans-Regular.ttf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glyphcommands(f, ch):\n",
    "    return Path([copy(cmd) for cmd in f.glyph(f.charmap[ord(ch)])])\n",
    "def advancefor(f, ch):\n",
    "    return f.advances[f.charmap[ord(ch)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's our source string (feel free to change this):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"x o x o x o x o x o x o x o x o x o x o\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the `render()` function for this example. Some notes:\n",
    "\n",
    "* You *need* to draw a background for the video to work! Flat pages have a transparent background by default, and the encoded video will show transparent backgrounds as all black. If you want the letters in this example to show up, you need to draw a white background on every frame.\n",
    "* If you're using a random number generator, either seed the generator with the same seed on every frame (as discussed in the [interactive widgets notebook](interactive-widgets.ipynb)) or use a random number generation technique (like [simplex noise](https://github.com/lmas/opensimplex) that allows you to ask for random numbers at particular seed values.\n",
    "* In the example below, the `end_frame` variable specifies how many frames the animation should last; the `fraction` variable inside the function calculates a value from 0 to 1 that indicates how much of the animation has passed given a particular `step` value. This is then used as a multiplier on the random values added to the `x` and `y` coordinates of each glyph. (Subtracting this value from 1, as I did below, essentially \"reverses\" the animation, moving the characters back into position instead of moving them progressively further away.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_frame = 600\n",
    "def render(step=0):\n",
    "    np.random.seed(12345)\n",
    "    page = document(500, 500, 'pt').addpage()\n",
    "    bg_pen = shape().nostroke().fill(rgb(255-step, 255-step*2, step*3))\n",
    "    page.place(bg_pen.rectangle(0, 0, 300*step/100, 90*step/100))\n",
    "    pen = shape().nostroke().fill(rgb(step, 0, 0))\n",
    "    factor = 36 / f.density\n",
    "    cx = 0\n",
    "    fraction = 1 - (step / end_frame)\n",
    "    for x in range(60):\n",
    "        for ch in s:\n",
    "            glyph_path = (glyphcommands(f, ch)\n",
    "                          .scale(factor)\n",
    "                          .translate(cx + (np.random.normal(step, 30) * fraction * x),\n",
    "                                     60 + (np.random.normal(x*100, 30) * fraction * x)))\n",
    "            page.place(pen.path(glyph_path))\n",
    "            \n",
    "        cx += advancefor(f, ch) * factor / 100\n",
    "    return page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Render and show at a particular frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show(render(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And preview with `widgets.interact()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.interact(lambda step: show(render(step)),\n",
    "                 step=widgets.Play(min=0, max=end_frame, interval=1000/30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(The `lambda step: show(render(step))` syntax there is a shorthand way of writing the `show_and_render()` function from above. [More on lambda functions.](https://realpython.com/python-lambda/))\n",
    "\n",
    "Finally, the code below writes each of the frames, from zero up to `end_frame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(end_frame):\n",
    "    fname = f\"render/image{i:05}.png\"\n",
    "    png_data = page2png(render(i))\n",
    "    with open(fname, \"wb\") as fh:\n",
    "        fh.write(png_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we convert those frames to mp4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -loglevel warning -y \\\n",
    "    -framerate 30 -f image2 -i render/image%05d.png \\\n",
    "    -vcodec libx264 -crf 10 -pix_fmt yuv420p render/output.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dancing asemic forms (advanced)\n",
    "\n",
    "The code below makes animated versions of the glyphs described in the [k-means glyphs](kmeans-glyphs.ipynb) notebook. First, here's a copy of the necessary function for producing a single glyph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_glyph(n_clusters=6):\n",
    "    data = np.random.uniform(low=-0.5, high=0.5, size=(500, 2))\n",
    "    km = MiniBatchKMeans(n_clusters=n_clusters, max_iter=25)\n",
    "    km.fit(data)\n",
    "    np.random.shuffle(km.cluster_centers_)\n",
    "    return Polyline(km.cluster_centers_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below draws a single glyph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glyph = kmeans_glyph(10).scale(100).translate(50, 50)\n",
    "glyph_poly = glyph.fancy_curve(samples_per=24,\n",
    "                               thicknesses=[2.5, 1.5, 0.5, 2],\n",
    "                               tightness=-0.5)\n",
    "page = document(100, 100, 'mm').addpage()\n",
    "brush = shape().nostroke().fill(rgb(40, 40, 40))\n",
    "page.place(brush.polygon(glyph_poly))\n",
    "show(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below generates two glyphs. Because the glyphs have the same number of points, we can smoothly interpolate between them using numpy's [`np.linspace()` function](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linspace.html) on the Polyline's `.vertices` (i.e., the underlying numpy array). The resulting value is an array of `n_frames` with one entry per intermediate point on the interpolation between the two forms. This `render()` function draws a fancy curve from the `Polyline` produced at each point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = 25\n",
    "glyph_a = kmeans_glyph(10).scale(100).translate(50, 50)\n",
    "glyph_b = kmeans_glyph(10).scale(100).translate(50, 50)\n",
    "interp = np.linspace(glyph_a.vertices, glyph_b.vertices, n_frames+1)\n",
    "def render(step=0):\n",
    "    this_glyph = Polyline(interp[step])\n",
    "    glyph_poly = this_glyph.augment().fancy_curve(samples_per=24,\n",
    "                               thicknesses=[2.5, 1.5, 0.5, 2],\n",
    "                               tightness=-0.5)\n",
    "    page = document(100, 100, 'mm').addpage()\n",
    "    brush = shape().nostroke().fill(rgb(40, 40, 40))\n",
    "    page.place(brush.polygon(glyph_poly))\n",
    "    return page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.interact(lambda step: show(render(step)),\n",
    "                 step=widgets.Play(min=0, max=n_frames, step=1, interval=1000/30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's one interpolation between two forms. The code in the cell below chains together multiple interpolations like this, forming one big list of interpolated forms. It ends with the same form it began with, so the video will loop seamlessly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "# canvas\n",
    "width = 250\n",
    "height = 250\n",
    "# number of interpolations and steps per interpolation\n",
    "n_interps = 12\n",
    "n_steps = 24\n",
    "interps = []\n",
    "# generate interpolations\n",
    "start = kmeans_glyph(10)\n",
    "current = start\n",
    "for i in range(n_interps):\n",
    "    end = kmeans_glyph(10)\n",
    "    interp = np.linspace(current.vertices, end.vertices, n_steps)\n",
    "    # make the last value of this interpolation the first of the next\n",
    "    current = end \n",
    "    interps.append(interp)\n",
    "# loop back to first\n",
    "interps.append(np.linspace(current.vertices, start.vertices, n_steps))\n",
    "# flatten list of lists\n",
    "interps = list(chain(*interps))\n",
    "\n",
    "def render(step=0):\n",
    "    this_glyph = Polyline(interps[step]).scale(width).translate(width*0.5, height*0.5)\n",
    "    glyph_poly = this_glyph.augment().fancy_curve(samples_per=24,\n",
    "                               thicknesses=[5, 3, 1, 4],\n",
    "                               tightness=-0.5)\n",
    "    page = document(width, height, 'mm').addpage()\n",
    "    background = shape().nostroke().fill(rgb(255, 255, 255))\n",
    "    brush = shape().nostroke().fill(rgb(40, 40, 40))\n",
    "    page.place(background.rectangle(0, 0, width, height))\n",
    "    page.place(brush.polygon(glyph_poly))\n",
    "    return page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Play widget preview:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.interact(lambda step: show(render(step)),\n",
    "                 step=widgets.Play(min=0, max=len(interps)-1, step=1, interval=1000/30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to write the frames. I've put a little ad-hoc progress counter in the cell below, since it can take a bit of time to export each frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(interps))\n",
    "for i in range(len(interps)):\n",
    "    print(i, end=\" \")\n",
    "    fname = f\"render/image{i:05}.png\"\n",
    "    png_data = page2png(render(i))\n",
    "    with open(fname, \"wb\") as fh:\n",
    "        fh.write(png_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aaaand convert to mp4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -loglevel warning -y \\\n",
    "    -framerate 30 -f image2 -i render/image%05d.png \\\n",
    "    -vcodec libx264 -crf 10 -pix_fmt yuv420p render/output.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking Flat `image().png()` versus CairoSVG `svg2png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import cairosvg\n",
    "%timeit cairosvg.svg2png(render(random.randrange(0, 30)).svg(), dpi=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit render(random.randrange(0, 30)).image(ppi=72, kind='rgb').png()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
